import{_ as n,c as a,a as s,o as e}from"./app-neTUUq9d.js";const l={};function p(o,t){return e(),a("div",null,t[0]||(t[0]=[s(`<h1 id="《智能体人才认证》课程笔记" tabindex="-1"><a class="header-anchor" href="#《智能体人才认证》课程笔记"><span>《智能体人才认证》课程笔记</span></a></h1><h2 id="_1-chatgpt原理" tabindex="-1"><a class="header-anchor" href="#_1-chatgpt原理"><span>1.ChatGPT原理</span></a></h2><h3 id="_1-1-大语言模型" tabindex="-1"><a class="header-anchor" href="#_1-1-大语言模型"><span>1.1 大语言模型</span></a></h3><p>大语言模型本质为<strong>概率模型</strong>。</p><p><strong>流式输出</strong>，按照概率，逐字生成回复内容。</p><p>示例：</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code class="language-text"><span class="line">你 （你：99%，我：1%，他：0%）</span>
<span class="line">你好 （好：80%，是：18%，的：2%）</span>
<span class="line">你好吗 （吗：99%，逗号：1%）</span>
<span class="line">...</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>当前的大语言模型基本都基于<strong>Transformer神经网络</strong>构建。<br> 由2部分组成：</p><ul><li>Encoder:语言理解，语言编码</li><li>Decoder:语言解码，语言生成</li></ul><p>以Encoder为主要结构的语言模型：</p><ul><li>BERT（谷歌）、DistilBERT、XLM...</li></ul><p>以Decoder为主要结构的语言模型：</p><ul><li>GPT（OpenAI）、CTRL...</li></ul><p>以Encoder+Decoder为主要结构的语言模型：</p><ul><li>T5、BART、BigBird...</li></ul><p>BERT模型不太出圈，原因是它基于编码器结构，理解识别语义能力突出，但生成能力较弱。</p><p>而GPT模型在GPT-2，GPT-3阶段时，同样离用户很远，但凭借下面的优化，使其变得越来越友好：</p><ul><li><strong>指令微调</strong></li><li><strong>基于人类反馈的强化学习（RLHF）</strong></li></ul><h3 id="_1-2-chatgpt" tabindex="-1"><a class="header-anchor" href="#_1-2-chatgpt"><span>1.2 ChatGPT</span></a></h3><p>发展历程</p><table><thead><tr><th>年份</th><th>大语言模型</th><th>介绍</th></tr></thead><tbody><tr><td>2013</td><td>Word2Vec</td><td>单词编码</td></tr><tr><td>2018</td><td>GPT</td><td>单向语言模型（上文编码）</td></tr><tr><td>2018</td><td>BERT</td><td>双向语言模型（上下文编码）</td></tr><tr><td>2019</td><td>GPT-2</td><td>大模型（15亿参数）；大数据量（40G）</td></tr><tr><td>2020</td><td>GPT-3</td><td>更大模型（1750亿参数）；大数据量（45T）</td></tr><tr><td>2022</td><td>InstructGPT</td><td>指令微调</td></tr><tr><td>2022</td><td>ChatGPT</td><td>RLHF，基于人类反馈的强化学习</td></tr></tbody></table><h2 id="_2-大模型提示词工程基础" tabindex="-1"><a class="header-anchor" href="#_2-大模型提示词工程基础"><span>2. 大模型提示词工程基础</span></a></h2><blockquote><p>研究的是“如何能让大模型更容易输出自己想要的内容”</p></blockquote><p>关键要素：</p><ul><li>选择与设计</li><li>优化策略</li><li>效果评估</li></ul><p>应用场景：</p><ul><li>文章生成</li><li>机器翻译</li><li>问答系统</li><li>文章摘要</li><li>数据生成</li><li>数据打标</li><li>意图识别</li><li>本地知识库回答</li></ul><p>基本要素：</p><ul><li>指令（任务要明确）</li><li>上下文</li><li>输入数据</li><li>输出指示（限制输出的内容、格式）</li></ul><p>使用技巧：</p><ul><li>明确提出应该做什么，不应该做什么</li><li>提供输出的格式提示</li><li>提供输出的示例</li><li>增加角色或场景</li></ul><p>进阶内容：</p><ul><li><strong>少样本提示</strong></li><li><strong>链式思考（CoT）</strong>：对于属于复杂推理的任务，不要求大模型一步到位输出推理结果，而是分步骤，这样得到的答案更准确。</li><li><strong>检索增强生成（RAG）</strong>：从向量数据库获取专业知识</li><li><strong>自动推理并使用工具（ART）</strong>：从任务库获取案例、或调用外部工具得到输出，然后整合</li><li><strong>ReAct提示</strong></li><li><strong>自我反思（Reflexion）</strong></li></ul><p>提示词参数调优：</p><table><thead><tr><th>参数</th><th>严谨任务</th><th>创意任务</th></tr></thead><tbody><tr><td>温度（随机性）</td><td>0~0.3</td><td>0.7~1</td></tr><tr><td>核采样（随机性）</td><td>0.1~0.3</td><td>0.7~1</td></tr><tr><td>频率惩罚</td><td>0.5~1</td><td>0~0.5</td></tr><tr><td>重复惩罚</td><td>0.3~0.7</td><td>0~0.5</td></tr></tbody></table><h2 id="_3-提示词工程项目实战-从0到1" tabindex="-1"><a class="header-anchor" href="#_3-提示词工程项目实战-从0到1"><span>3. 提示词工程项目实战（从0到1）</span></a></h2><p>Prompt工程，也叫提示词工程，是<strong>业务服务</strong>与<strong>大模型</strong>的中枢。</p><p>通过提示词工程，我们可以搭建出在某个场景、某个任务专用的机器人；</p><p>同时，可以通过<strong>整合、编排</strong>多个提示词工程，来完善、丰富其功能。</p><h3 id="_3-1-案例1-对问答机器人的回答打分、润色" tabindex="-1"><a class="header-anchor" href="#_3-1-案例1-对问答机器人的回答打分、润色"><span>3.1 案例1：对问答机器人的回答打分、润色</span></a></h3><p>步骤：</p><ol><li>搭建大模型</li><li>搭建知识库（文档库-&gt;向量数据库）</li><li>在RAG（检索增强生成）阶段，<strong>通过Prompt工程</strong>，对检索到的信息进行打分、润色</li></ol><p>输入：</p><ul><li>用户提问</li><li>向量数据库-知识</li></ul><p>输出：</p><ul><li>机器人答复</li></ul><h3 id="_3-2-案例2-文本提取-分类" tabindex="-1"><a class="header-anchor" href="#_3-2-案例2-文本提取-分类"><span>3.2 案例2：文本提取&amp;分类</span></a></h3><p>步骤：</p><ol><li>用户给出一篇文章</li><li><strong>通过Prompt工程</strong>，<strong>分步</strong>提炼出事实、事件，对其归纳整理，进而为文章打标签（中文、情感、青年...）</li></ol><p>输入：</p><ul><li>文本原文</li><li>业务分类标签</li></ul><p>输出：</p><ul><li>数据标签映射关系</li></ul><h3 id="_3-3-案例3-文案创作" tabindex="-1"><a class="header-anchor" href="#_3-3-案例3-文案创作"><span>3.3 案例3：文案创作</span></a></h3><p>步骤：</p><ol><li><strong>通过Prompt工程</strong>，分析出热门案例的规律、风格</li><li><strong>通过Prompt工程</strong>，根据思路写出某个商品的热门文案</li></ol><p>输入：</p><ul><li>文案示例</li><li>商品营销信息</li></ul><p>输出：</p><ul><li>商品宣传文案</li></ul><h3 id="_3-4-什么是token" tabindex="-1"><a class="header-anchor" href="#_3-4-什么是token"><span>3.4 什么是Token</span></a></h3><p>Token是用来计算用户文本输入的长度的。</p><p>OpenAI使用了一种称作<strong>Byte Pair Encoding（BPE）</strong> 的计算方法，将文本转换为Token。</p><p>规则：</p><ol><li>BPE根据词频合并最常见的字符对，形成新的子词单元，把它当作一个Token（如北京）。</li><li>不常见的英文单词，则会按音节拆分成多个Token（如agnostic）。</li></ol><p>示例：</p><ul><li>中文 <ul><li>你好 --- 2 Token</li><li>龙 --- 1 Token</li><li>北京 --- 1 Token</li></ul></li><li>英文 <ul><li>I love you --- 3 Token （3个常见单词）</li><li>task-specific --- 3 Token （横杠+2个常见单词）</li><li>task-agnostic --- 4 Token （横杠+1个常见单词task+1个不常见单词agnostic）</li></ul></li><li>日期 <ul><li>2025-05-05 --- 5 Token （2个横杠+年月日）</li></ul></li></ul><h3 id="_3-5-chatgpt接口入参学习" tabindex="-1"><a class="header-anchor" href="#_3-5-chatgpt接口入参学习"><span>3.5 ChatGPT接口入参学习</span></a></h3><table><thead><tr><th>参数</th><th>数据类型</th><th>说明</th></tr></thead><tbody><tr><td>model</td><td>String</td><td>要使用的模型的ID</td></tr><tr><td>Message</td><td>Json</td><td>存放提示词。可包括：对话预设的prompt、用户提问prompt、助手生成的内容</td></tr><tr><td>Temperature</td><td>Double</td><td>温度采样，介于0~2之间，值越高，输出内容会更加随机</td></tr><tr><td>top_p</td><td>Double</td><td>核采样</td></tr><tr><td>frequency_penality</td><td>Double</td><td>重复度惩罚因子，介于-2.0~2.0之间</td></tr><tr><td>presence_penality</td><td>Double</td><td>控制主题的重复度，介于-2.0~2.0之间</td></tr></tbody></table><p>OpenAI论坛给出的参数设置参考：</p><table><thead><tr><th>场景</th><th>Temperature</th><th>Top_p</th></tr></thead><tbody><tr><td>代码生成</td><td>0.2</td><td>0.1</td></tr><tr><td>代码注释生成</td><td>0.3</td><td>0.2</td></tr><tr><td>创意写作</td><td>0.7</td><td>0.8</td></tr><tr><td>聊天机器人回复</td><td>0.5</td><td>0.5</td></tr><tr><td>数据分析脚本编写</td><td>0.2</td><td>0.1</td></tr></tbody></table><h4 id="message" tabindex="-1"><a class="header-anchor" href="#message"><span>Message</span></a></h4><p>示例：<br> 【输入参数】</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json"><pre><code class="language-json"><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;Message&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span><span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;content&quot;</span><span class="token operator">:</span><span class="token string">&quot;你是一个资深历史老师&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;content&quot;</span><span class="token operator">:</span><span class="token string">&quot;李白是哪一年出生？&quot;</span><span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>【输出参数】</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json"><pre><code class="language-json"><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;Message&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span><span class="token string">&quot;system&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;content&quot;</span><span class="token operator">:</span><span class="token string">&quot;你是一个资深历史老师&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;content&quot;</span><span class="token operator">:</span><span class="token string">&quot;李白是哪一年出生？&quot;</span><span class="token punctuation">}</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">{</span><span class="token property">&quot;role&quot;</span><span class="token operator">:</span><span class="token string">&quot;assistant&quot;</span><span class="token punctuation">,</span><span class="token property">&quot;content&quot;</span><span class="token operator">:</span><span class="token string">&quot;公元701年&quot;</span><span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>system：<strong>对助手的预设prompt</strong>。例如，你希望助手拥有的角色、能力、遵从的规则等</li><li>user: <strong>用户输入的问题</strong>。</li><li>role: <strong>助手输出的回答</strong>。</li></ul><h2 id="_4-图文生成基础" tabindex="-1"><a class="header-anchor" href="#_4-图文生成基础"><span>4. 图文生成基础</span></a></h2><p>当你想生成“类似某个图风格”的图片</p><ul><li>可以先拿一张原图生成提示词，然后按你的需求对提示词进行修改</li></ul><p>提示词示例：</p><ul><li>主要场景 + 场景物体 + 风格/颜色/材质 + 构图/镜头 + 画质</li><li>主体，他们在干什么 + 环境在哪里，元素有什么 + 风格/颜色/材质 + 构图/镜头 + 画质</li><li>两只可爱的兔子，抱着月饼 + 坐在月饼上，背景是巨大月亮 + 卡通海报，插画风格 + 近景 + 高清，超细节</li></ul><h2 id="_5-rag" tabindex="-1"><a class="header-anchor" href="#_5-rag"><span>5. RAG</span></a></h2><p>RAG是一个外部知识库，能在不改变模型参数的情况下，对模型进行调优。</p><p>大模型能通过以下方式<strong>学习知识</strong>：</p><ul><li>预训练时，从训练数据中学习</li><li>调用MCP格式的API（如天气 MCP-API）</li><li>RAG（多源检索，如网页/数据库/API）</li></ul><h3 id="_5-1-如何构建rag知识库" tabindex="-1"><a class="header-anchor" href="#_5-1-如何构建rag知识库"><span>5.1 如何构建RAG知识库</span></a></h3><p>Python + LangChain + 向量数据库</p><p>本质是将用户提供的文档，整理并保存到<strong>向量数据库</strong>中。</p><p>常用的向量数据库：</p><table><thead><tr><th>类型</th><th>代表产品</th><th>核心优势</th><th>适用场景</th></tr></thead><tbody><tr><td>专用向量数据库</td><td>Milvus/Zilliz Cloud</td><td>分布式架构、高吞吐量、支持亿级向量，提供多模态检索和混合搜索</td><td>大规模企业级RAG（如金融、电商知识库）</td></tr><tr><td>轻量级嵌入式库</td><td>FAISS</td><td>本地化部署、GPU加速、与PyTorch/TensorFlow深度集成</td><td>研究实验、小规模本地应用（如个人知识助手）</td></tr><tr><td>云托管服务</td><td>Pinecone</td><td>全托管、自动扩缩容、实时更新索引，无需运维</td><td>商业项目快速上线（如SaaS客服系统）</td></tr><tr><td>扩展型传统数据库</td><td>PGVector (PostgreSQL扩展)</td><td>兼容SQL生态，支持向量+关系型数据联合查询</td><td>已有PostgreSQL的企业增量升级（如文档管理系统）</td></tr><tr><td>多模态增强数据库</td><td>Weaviate</td><td>内置知识图谱、支持文本/图像/视频向量化，GraphQL接口</td><td>复杂语义搜索（如医疗影像报告分析）</td></tr><tr><td>索引擎集成方案</td><td>OpenSearch/ElasticSearch</td><td>结合关键词检索与向量搜索，支持混合排序</td><td>需要全文检索+语义搜索的场景（如法律条文查询）</td></tr><tr><td>新兴开源选择</td><td>LanceDB</td><td>基于Arrow格式，零拷贝访问，支持SIMD/GPU加速</td><td>高性能边缘计算（如IoT设备实时分析）</td></tr></tbody></table><h3 id="_5-2-如何调用rag" tabindex="-1"><a class="header-anchor" href="#_5-2-如何调用rag"><span>5.2 如何调用RAG</span></a></h3><p>通过LangChain等架构工具，在编排的工作流中增加对RAG的调用。</p><h3 id="_5-3-大模型生成回答的原理" tabindex="-1"><a class="header-anchor" href="#_5-3-大模型生成回答的原理"><span>5.3 大模型生成回答的原理</span></a></h3><ol><li>用户实时问题 ---&gt; 用户提示词</li><li>知识库 ---&gt; 知识提示词</li><li>任务定制 ---&gt; 系统提示词</li><li>LLM获取上面的3种提示词，最终整合成回答</li></ol><h3 id="_5-4-rag的发展" tabindex="-1"><a class="header-anchor" href="#_5-4-rag的发展"><span>5.4 RAG的发展</span></a></h3><ul><li>Native RAG（固定流程，直接从向量数据库查询，并且结合系统提示词、用户提示词生成回答）</li><li>Advanced RAG（Native RAG基础上，增加了重排、过滤等步骤。依然是固定流程）</li><li>Modular RAG（将阅读、搜索、重写、过滤等能力模块化，并且由大模型决定执行流程）</li></ul>`,97)]))}const d=n(l,[["render",p]]),r=JSON.parse('{"path":"/AI/%E6%99%BA%E8%83%BD%E4%BD%93%E4%BA%BA%E6%89%8D%E8%AE%A4%E8%AF%81%E7%AC%94%E8%AE%B0.html","title":"《智能体人才认证》课程笔记","lang":"en-US","frontmatter":{"title":"《智能体人才认证》课程笔记"},"git":{"updatedTime":1750240340000,"contributors":[{"name":"dongyz8","username":"dongyz8","email":"dongyz8@gdii-yueyun.com","commits":5,"url":"https://github.com/dongyz8"}],"changelog":[{"hash":"ad8fc1a188d6829c38676e985c8e2097211af10d","time":1750240340000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"},{"hash":"80e0827d475a79fb45454cb067b28fc2e737faa6","time":1749806079000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"},{"hash":"e6829e5801e5155e8c0b2e1787b283c97aab9e83","time":1749205204000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"},{"hash":"a0349710a45e682e020307e533ec0b69a438b60c","time":1748600545000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"},{"hash":"c4850efc474770a7739428e0a883bf8bb9497131","time":1747994383000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"}]},"filePathRelative":"AI/智能体人才认证笔记.md"}');export{d as comp,r as data};
