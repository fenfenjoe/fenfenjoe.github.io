import{_ as a,c as t,a as s,o as i}from"./app-iMoEB5u2.js";const n={};function e(o,l){return i(),t("div",null,l[0]||(l[0]=[s('<h1 id="es实战" tabindex="-1"><a class="header-anchor" href="#es实战"><span>ES实战</span></a></h1><h3 id="如何保证mysql数据表与es索引的数据一致性" tabindex="-1"><a class="header-anchor" href="#如何保证mysql数据表与es索引的数据一致性"><span>如何保证MYSQL数据表与ES索引的数据一致性</span></a></h3><p>【需求描述】<br> 我在mysql数据库有一张表A，为了加快搜索速度，将数据迁移到了ES。<br> 但表A仍然会有增量数据进来，对于这些增量数据，要如何保证数据写进了MYSQL后，也会写进ES呢？</p><p>【解决方案】</p><ol><li>数据双写</li><li>MQ异步同步</li><li>基于Binlog实现数据同步（Canal）</li></ol><p>【数据双写】</p><p><strong>原理</strong>：在程序中，在写入数据时，先写入数据到Mysql，然后再写入到ES。<br><strong>优点</strong>：实现简单，时效性高<br><strong>缺点</strong>：硬编码问题严重（每个表都要重写一次）；如果服务或ES宕机，会有数据丢失风险</p><p>【MQ异步同步】</p><p><strong>原理</strong>：在程序中，在写入数据时，先写入数据到Mysql，然后再写入一条消息到MQ，通过MQ告诉ES需要进行数据同步。<br><strong>优点</strong>：</p><ul><li>这个方案最直接的点就是性能高，并且实现了业务的解耦合，并且可以利用 MQ 的重试机制，在写入失败的时候进行重试，降低了数据丢失的风险。</li><li>这样还支持多个数据源的写入，提高了扩展性，不会出现由于单个数据源写入异常从而导致其他数据源写入受到影响的问题。<br><strong>缺点</strong>：</li><li>硬编码问题，在接入新的数据源的时候需要实现新的消费者代码，代码侵入性较强</li><li>引入了消息队列，提高了运维的成本，增加了系统的复杂程度</li><li>可能出现延时问题，因为消息队列是异步消费模型，用户写入的数据不一定可以马上看到结果，有一定的延迟。</li></ul><p>【Canal（基于Binlog实现数据同步）】</p><p><strong>原理</strong>：</p><ul><li>Mysql的主节点会将增删改操作都写入binlog日志</li><li>Canal伪装成Mysql的从节点，订阅Mysql的binlog日志 <strong>优点</strong>：</li><li>没有代码侵入，没有硬编码</li><li>原有的系统没有任何变化，可以实现无感知，性能较高</li><li>业务解耦合，这个和消息队列是差不多实现思路的，不过这个不需要关注原来系统的业务实现</li></ul>',13)]))}const g=a(n,[["render",e]]),c=JSON.parse('{"path":"/database/elasticSearch/ES%E5%AE%9E%E6%88%98.html","title":"ES实战","lang":"en-US","frontmatter":{"title":"ES实战"},"git":{"updatedTime":1732669486000,"contributors":[{"name":"dongyz8","username":"dongyz8","email":"dongyz8@gdii-yueyun.com","commits":1,"url":"https://github.com/dongyz8"}],"changelog":[{"hash":"2107fe45a32694cb96e49385ca5e0106c7ec14a9","time":1732669486000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"}]},"filePathRelative":"database/elasticSearch/ES实战.md"}');export{g as comp,c as data};
