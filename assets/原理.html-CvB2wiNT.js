import{_ as a,c as e,a as o,o as i}from"./app-neTUUq9d.js";const n="/images/Kafka.png",l={};function t(s,r){return i(),e("div",null,r[0]||(r[0]=[o('<h1 id="原理" tabindex="-1"><a class="header-anchor" href="#原理"><span>原理</span></a></h1><h2 id="_0-kafka集群" tabindex="-1"><a class="header-anchor" href="#_0-kafka集群"><span>0.kafka集群</span></a></h2><figure><img src="'+n+`" alt="kafka.png" tabindex="0" loading="lazy"><figcaption>kafka.png</figcaption></figure><p><strong>生产者（Producer）</strong><br> 发送消息的程序</p><p><strong>消息（Message）</strong><br> 存储在分区中，一个分区就是一个消息队列；<br> 无论是否被消费，消息都会存储在消息队列中；<br> 消息有过期时间，过期后会被自动清除；</p><p><strong>代理（Broker）</strong><br> 相当于一台物理主机。上面运行着kafka进程。存储kafka消息的实际地方。<br> Broker又分为Controller Broker和普通的Broker。</p><blockquote><p>Controller Broker，又称为Leader Broker，主要作用是在ZooKeeper 的帮助下管理和协调整个 Kafka 集群。</p><ul><li>创建、删除主题，增加分区并分配leader分区</li><li>集群Broker管理（新增 Broker、Broker 主动关闭、Broker 故障)</li><li>preferred leader选举</li><li>分区重分配<br> 集群启动时，会从所有Broker中选举出一个作为Controller。</li></ul></blockquote><p><strong>Zookeeper</strong><br> 负责存储Broker的元信息，包括Broker保存了哪些Topic，有哪些分区Partition等。</p><p><strong>消费者（Consumer）</strong><br> 接收消息的程序</p><p><strong>消费者组（Consumer Group）</strong><br> 多个消费者可以划分成一个消费者组。每个消费者组对一条消息只能处理一次。<br> 消费者默认属于default消费者组。</p><p><strong>主题（Topic）</strong><br> 逻辑上的一个消息组。一个Topic还可以分成多个Partitions，存在不同的Broker里。</p><p><strong>分区（Partitions）</strong><br> Partitions是存储的最小单位。<br> Partitions可以理解为是Topic的“分表”，<strong>每个Partitions保存着Topic的一部分数据</strong>。<br> 一个Broker里可存储多个Partitions。<br> 同一消费者组中，每个Partition只能由一个消费者负责。</p><p><strong>副本（Replication）</strong><br> Replication是分区的副本，副本不会跟分区存到同一个Broker上。<br> 分区的副本数不能大于Broker的数量。否则会抛出异常。</p><p><strong>偏移量（Partition Offset）</strong><br> 可理解为“指针”、“分区消息数组的下标”；<br> 分区会为不同的消费者组维护各自的偏移量；<br> 表示消费者组消费到分区中的哪一条消息；</p><h2 id="_1-kafka是做什么的" tabindex="-1"><a class="header-anchor" href="#_1-kafka是做什么的"><span>1.kafka是做什么的？</span></a></h2><p>一个分布式消息队列中间件（MQ）。</p><p>kafka负责接收生产者（APP）发送过来的消息，并将这些消息转发给消费者（另一些APP）；</p><h2 id="_2-kafka消息类型" tabindex="-1"><a class="header-anchor" href="#_2-kafka消息类型"><span>2.kafka消息类型</span></a></h2><ul><li>Avro消息（官方推荐）</li><li>Json</li><li>XML</li><li>Java Bean</li></ul><h2 id="_3-kafka消息如何流转" tabindex="-1"><a class="header-anchor" href="#_3-kafka消息如何流转"><span>3.kafka消息如何流转</span></a></h2><p><strong>创建主题</strong><br> 需要先在kafka创建好<strong>主题（Topic）</strong>，kafka会根据接收到的消息按主题进行分类；<br> 创建主题时，还需要指定主题的<strong>分区数（partitions）</strong> 和<strong>副本（replication-factor）数</strong>。</p><ul><li><strong>分区数</strong>，就是将主题分成多少份保存，一般等于或少于服务器数量</li><li><strong>副本数</strong>，就是每个分区要多少个备份，一般等于或少于服务器数量</li></ul><p><strong>消息发送</strong><br> 生产者在发送消息前，需要指定消息发送到哪个主题(Topic)。</p><p>kafka实际用分区(partition)来存储消息。因此生产者还需要指定将消息发送到哪个分区。</p><blockquote><p><strong>生产者如何选择分区(partition)?</strong><br> 生产者可从kafka集群的任意broker中，获得所有kafka broker的元信息。包括topic有多少个分区(partition)，各个分区的leader在哪个broker等。<br> 取得partition地址列表后，Producer需要指定负载均衡策略，主动选择消息发送到分区的策略。<br> 有以下几种策略：</p><ul><li>轮询</li><li>随机</li><li>基于某个key</li></ul></blockquote><p>配置好负载均衡策略后，每次Producer发送消息时，便会自动根据策略选择分区(partition)。</p><p><strong>消息接收</strong><br> 发送消息时会指定<strong>主题（Topic）</strong>，消费者只接收自己关注的主题的消息；</p><blockquote><p>就像微博、Twitter这样，关注某个博主后就会收到该博主的动态信息。</p></blockquote><p>还可以对消费者分组（Group）。但同一组内的消费者，不会接收到同一分区的消息。</p><blockquote><p>这样设计是为了确保分组（Group）接收到主题（Topic）的消息是没有重复的</p></blockquote><p><strong>消息消费</strong></p><ol><li>消费者和Kafka各自维护着该Topic的一个偏移量（offset），表示它已经成功消费到哪个位置。</li><li>当有新消息到达Kafka中，Kafka不会主动推新消息给消费者；相反，由消费者在下一次拉取请求中发现这些新消息。</li><li>消费者通过<strong>长轮询（long poll）</strong> 机制，去监听Topic是否有新消息。</li><li>消费者通过比较<strong>上次提交的偏移量</strong>和<strong>Kafka中存储的偏移量</strong>来确定Topic中是否有新消息可以消费。</li><li>当处理完消息后，消费者可以选择<strong>手动提交偏移量</strong>或<strong>自动提交偏移量</strong></li></ol><h2 id="_4-kafka的消息如何持久化" tabindex="-1"><a class="header-anchor" href="#_4-kafka的消息如何持久化"><span>4.kafka的消息如何持久化？</span></a></h2><p>消息保存在<strong>日志文件</strong>中；新增一条消息 = 向日志文件追加内容。</p><p>通过内存来缓存消息，并会尽快写入到日志文件中。</p><p>写入到日志文件的消息<strong>默认会保留7天</strong>。</p><h2 id="_5-kafka如何做负载均衡" tabindex="-1"><a class="header-anchor" href="#_5-kafka如何做负载均衡"><span>5.kafka如何做负载均衡？</span></a></h2><p><strong>对Producer的负载均衡：</strong><br> 对于某个Topic，kafka会将Zookeeper中维护的该Topic的“存活Broker列表/存活Partition列表”提供给Producer，由Producer自己决定将消息发送到哪里（由Producer自己做负载均衡）。</p><p><strong>对Consumer的负载均衡：</strong><br> 在Consumer Group中，有Consumer的加入或离开，便会触发Partition均衡：</p><ul><li><p>假设有4个Consumer（ABCD），8个Partition（12345678）<br> 每个Consumer两个分区：A=12,B=34,C=56,D=78</p></li><li><p>假设有8个Consumer（ABCDEFGH），4个分区（1234）<br> 因为同一Group中的Consumer不能消费同一个分区，因此：A=1,B=2,C=3,D=4,E=null,...</p></li></ul><h2 id="_6-kafka的副本-replication-机制" tabindex="-1"><a class="header-anchor" href="#_6-kafka的副本-replication-机制"><span>6.kafka的副本（replication）机制？</span></a></h2><p>kafka可为每个partition设置副本，副本会被存储到不同的Broker上，并且副本的数据与partition本身会保持一致。</p><p>副本分为两种类型：Leader和Follower；</p><p>Leader负责处理read-write请求，Follower负责同步Leader中的数据；</p><p>每个partition的副本中，都会有1个Leader和0~N个Follower；</p><p>只要有一个副本存活，那么该partition也能正常工作；</p><p><strong>当有新消息进来，所有Follower都将消息保存成功后，这条消息才算Commited，Consumer才能消费这条消息。</strong></p><h2 id="_7-什么是ar、isr、osr" tabindex="-1"><a class="header-anchor" href="#_7-什么是ar、isr、osr"><span>7.什么是AR、ISR、OSR？</span></a></h2><p>AR：Assigned Repllicas，即副本。分区的所有副本统称AR。<br> ISR：In-Sync Replicas，分区中能与leader保持一定程度同步的副本，统称ISR。<br> OSR：Out-Sync Relipcas，分区中与leader相比滞后过多的副本，统称OSR。<br> 因此AR=ISR+OSR。<br> kafka可以忍受的“滞后”的程度可以通过参数配置。</p><h2 id="_8-kafka的选举机制" tabindex="-1"><a class="header-anchor" href="#_8-kafka的选举机制"><span>8.kafka的选举机制</span></a></h2><ul><li>kafka在三个地方用到了选举机制： <ul><li>Broker之间选leader</li><li>Partition的多副本之间选leader</li><li>消费者组中消费者之间选leader</li></ul></li></ul><p>8.1【Broker Leader】</p><ul><li><p>Leader的作用：</p><ul><li>创建、删除主题，增加分区并分配leader分区</li><li>集群Broker管理（新增 Broker、Broker 主动关闭、Broker 故障)</li><li>preferred leader选举</li><li>分区重分配</li></ul></li><li><p>怎样触发Leader选举：</p><ul><li>kafka集群启动</li></ul></li></ul><p>8.2【Replica Leader】</p><ul><li><p>Leader的作用：</p><ul><li><strong>生产者</strong>：所有消息必须发送到 Leader（生产者直接与 Leader 通信）</li><li><strong>消费者</strong>：所有消息必须从 Leader 读取</li><li><strong>关键点</strong>：Follower 副本不直接服务客户端，仅负责从 Leader 同步数据</li></ul></li><li><p>怎样触发Leader选举（Rebalance）：</p><ul><li>Leader 副本下线</li><li>手动运行 kafka-reassign-partitions 命令</li><li>设置broker端参数auto.leader.rebalance.enable为true（默认值），这样controller定时自动调整preferred leader</li><li>Leader 副本所在Broker 正常关闭</li></ul></li><li><p>如何选举：</p><ul><li>从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合</li><li>调用配置的分区选择算法选择分区的leader(默认：当前分区副本列表(AR)中首个存活且处于 ISR 列表中的副本作为 Leader 副本)</li></ul></li></ul><h2 id="_9-kafka集群的异常情况-脑裂" tabindex="-1"><a class="header-anchor" href="#_9-kafka集群的异常情况-脑裂"><span>9.kafka集群的异常情况：脑裂</span></a></h2><p>略</p><h2 id="_10-zookeeper在kafka集群中的作用" tabindex="-1"><a class="header-anchor" href="#_10-zookeeper在kafka集群中的作用"><span>10.Zookeeper在Kafka集群中的作用</span></a></h2><p>Broker、Consumer的注册中心；<br> 监控Partition Leader的存活性；</p><h2 id="_11-kafka能保证消息按顺序消费吗" tabindex="-1"><a class="header-anchor" href="#_11-kafka能保证消息按顺序消费吗"><span>11.kafka能保证消息按顺序消费吗？</span></a></h2><p>可以，但需要生产者在发消息时，设置一个key，然后kafka会根据这个key将消息都发往同一个partition中；<br> 然后，因为一个partition只能由同一消费者组中的一个消费者消费，所以便保证了顺序消费。</p><h2 id="_12-kafka消息中key参数的作用" tabindex="-1"><a class="header-anchor" href="#_12-kafka消息中key参数的作用"><span>12.kafka消息中key参数的作用</span></a></h2><ol><li><strong>分区路由控制</strong><br> Kafka 使用 key 的哈希值决定消息发送到哪个分区：</li></ol><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text"><pre><code class="language-text"><span class="line">分区号 = hash(key) % 分区总数</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li><strong>相同 key 的消息总是进入同一分区</strong></li><li><strong>不同 key 的消息可能分配到不同分区</strong></li><li><strong>无 key 的消息会轮询发送到各分区</strong></li></ul><ol start="2"><li><strong>保证消息顺序性</strong></li></ol><p>在 Kafka 中，单个分区内的消息是有序的。通过相同 key：</p><ul><li>确保相关消息（如同一订单的操作）被顺序处理</li><li>避免跨分区消费导致的乱序问题</li></ul><p>一般会用<strong>订单ID</strong>、<strong>用户ID</strong>、<strong>设备ID</strong>等作为Key</p>`,69)]))}const k=a(l,[["render",t]]),d=JSON.parse('{"path":"/mq/kafka/%E5%8E%9F%E7%90%86.html","title":"原理","lang":"en-US","frontmatter":{"title":"原理"},"git":{"updatedTime":1752834101000,"contributors":[{"name":"dongyz8","username":"dongyz8","email":"dongyz8@gdii-yueyun.com","commits":2,"url":"https://github.com/dongyz8"}],"changelog":[{"hash":"f57d30d02281ec9cc1098f316484f25d35df5ea7","time":1752834101000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"},{"hash":"3bf714608ba624a458ff2af68c9f2ca1b611e847","time":1752747333000,"email":"dongyz8@gdii-yueyun.com","author":"dongyz8","message":"commit"}]},"filePathRelative":"mq/kafka/原理.md"}');export{k as comp,d as data};
