---
title: 《智能体人才认证》课程笔记
---

# 《智能体人才认证》课程笔记

## 1.ChatGPT原理

### 1.1 大语言模型

大语言模型本质为**概率模型**。  

**流式输出**，按照概率，逐字生成回复内容。  

示例：
```  
你 （你：99%，我：1%，他：0%）
你好 （好：80%，是：18%，的：2%）
你好吗 （吗：99%，逗号：1%）
...
```

当前的大语言模型基本都基于**Transformer神经网络**构建。  
由2部分组成：
- Encoder:语言理解，语言编码
- Decoder:语言解码，语言生成

以Encoder为主要结构的语言模型：
- BERT（谷歌）、DistilBERT、XLM...

以Decoder为主要结构的语言模型：
- GPT（OpenAI）、CTRL...

以Encoder+Decoder为主要结构的语言模型：
- T5、BART、BigBird...


BERT模型不太出圈，原因是它基于编码器结构，理解识别语义能力突出，但生成能力较弱。  

而GPT模型在GPT-2，GPT-3阶段时，同样离用户很远，但凭借下面的优化，使其变得越来越友好：
- **指令微调**
- **基于人类反馈的强化学习（RLHF）**

### 1.2 ChatGPT

发展历程

| 年份    | 大语言模型        | 介绍                      |
|-------|--------------|-------------------------|
| 2013  | Word2Vec     | 单词编码                    |
| 2018  | GPT          | 单向语言模型（上文编码）            |
| 2018  | BERT         | 双向语言模型（上下文编码）           |
| 2019  | GPT-2        | 大模型（15亿参数）；大数据量（40G）    |
| 2020  | GPT-3        | 更大模型（1750亿参数）；大数据量（45T） |
| 2022  | InstructGPT  | 指令微调                    |
| 2022  | ChatGPT      | RLHF，基于人类反馈的强化学习        |


## 2. 大模型提示词工程基础

> 研究的是“如何能让大模型更容易输出自己想要的内容”

关键要素：
- 选择与设计
- 优化策略
- 效果评估

应用场景：
- 文章生成
- 机器翻译
- 问答系统
- 文章摘要
- 数据生成
- 数据打标
- 意图识别
- 本地知识库回答

基本要素：
- 指令（任务要明确）
- 上下文
- 输入数据
- 输出指示（限制输出的内容、格式）


使用技巧：
- 明确提出应该做什么，不应该做什么
- 提供输出的格式提示
- 提供输出的示例
- 增加角色或场景

进阶内容：
- **少样本提示**
- **链式思考（CoT）**：对于属于复杂推理的任务，不要求大模型一步到位输出推理结果，而是分步骤，这样得到的答案更准确。
- **检索增强生成（RAG）**：从向量数据库获取专业知识
- **自动推理并使用工具（ART）**：从任务库获取案例、或调用外部工具得到输出，然后整合
- **ReAct提示**
- **自我反思（Reflexion）**

提示词参数调优：

| 参数       | 严谨任务     | 创意任务   |
|----------|----------|--------|
| 温度（随机性）  | 0~0.3    | 0.7~1  |
| 核采样（随机性） | 0.1~0.3  | 0.7~1  |
| 频率惩罚     | 0.5~1    | 0~0.5  |
| 重复惩罚     | 0.3~0.7  | 0~0.5  |


## 3. 提示词工程项目实战（从0到1）

Prompt工程，也叫提示词工程，是**业务服务**与**大模型**的中枢。  

通过提示词工程，我们可以搭建出在某个场景、某个任务专用的机器人；  

同时，可以通过**整合、编排**多个提示词工程，来完善、丰富其功能。  


### 3.1 案例1：对问答机器人的回答打分、润色

步骤：
1. 搭建大模型
2. 搭建知识库（文档库->向量数据库）
3. 在RAG（检索增强生成）阶段，**通过Prompt工程**，对检索到的信息进行打分、润色

输入：
- 用户提问
- 向量数据库-知识

输出：
- 机器人答复

### 3.2 案例2：文本提取&分类

步骤：
1. 用户给出一篇文章
2. **通过Prompt工程**，**分步**提炼出事实、事件，对其归纳整理，进而为文章打标签（中文、情感、青年...）

输入：
- 文本原文
- 业务分类标签

输出：
- 数据标签映射关系


### 3.3 案例3：文案创作

步骤：
1. **通过Prompt工程**，分析出热门案例的规律、风格
2. **通过Prompt工程**，根据思路写出某个商品的热门文案

输入：
- 文案示例
- 商品营销信息

输出：
- 商品宣传文案


### 3.4 什么是Token

Token是用来计算用户文本输入的长度的。

OpenAI使用了一种称作**Byte Pair Encoding（BPE）** 的计算方法，将文本转换为Token。  

规则：
1. BPE根据词频合并最常见的字符对，形成新的子词单元，把它当作一个Token（如北京）。
2. 不常见的英文单词，则会按音节拆分成多个Token（如agnostic）。

示例：
- 中文
    - 你好 --- 2 Token
    - 龙  --- 1 Token
    - 北京 --- 1 Token
- 英文
    - I love you --- 3 Token （3个常见单词）
    - task-specific --- 3 Token （横杠+2个常见单词）
    - task-agnostic --- 4 Token （横杠+1个常见单词task+1个不常见单词agnostic）
- 日期
    - 2025-05-05 --- 5 Token （2个横杠+年月日）



### 3.5 ChatGPT接口入参学习

| 参数                 | 数据类型   | 说明                                        |
|--------------------|--------|-------------------------------------------|
| model              | String | 要使用的模型的ID                                 |
| Message            | Json   | 存放提示词。可包括：对话预设的prompt、用户提问prompt、助手生成的内容  |
| Temperature        | Double | 温度采样，介于0~2之间，值越高，输出内容会更加随机                |
| top_p              | Double | 核采样                                       |
| frequency_penality | Double | 重复度惩罚因子，介于-2.0~2.0之间                      |
| presence_penality  | Double | 控制主题的重复度，介于-2.0~2.0之间                     |


OpenAI论坛给出的参数设置参考：

| 场景       | Temperature | Top_p |
|----------|-------------|-------|
| 代码生成     | 0.2         | 0.1   |
| 代码注释生成   | 0.3         | 0.2   |
| 创意写作     | 0.7         | 0.8   |
| 聊天机器人回复  | 0.5         | 0.5   |
| 数据分析脚本编写 | 0.2         | 0.1   |


#### Message

示例：  
【输入参数】  
```json
{
  "model": 1,
  "Message": [
    {"role":"system","content":"你是一个资深历史老师"},
    {"role":"user","content":"李白是哪一年出生？"}
  ]
}
```

【输出参数】  
```json
{
  "model": 1,
  "Message": [
    {"role":"system","content":"你是一个资深历史老师"},
    {"role":"user","content":"李白是哪一年出生？"},
    {"role":"assistant","content":"公元701年"}
  ]
}
```

- system：**对助手的预设prompt**。例如，你希望助手拥有的角色、能力、遵从的规则等
- user: **用户输入的问题**。
- role: **助手输出的回答**。



## 4. 图文生成基础

当你想生成“类似某个图风格”的图片
- 可以先拿一张原图生成提示词，然后按你的需求对提示词进行修改

提示词示例：
- 主要场景 + 场景物体 + 风格/颜色/材质 + 构图/镜头 + 画质
- 主体，他们在干什么 + 环境在哪里，元素有什么 + 风格/颜色/材质 + 构图/镜头 + 画质
- 两只可爱的兔子，抱着月饼 + 坐在月饼上，背景是巨大月亮 + 卡通海报，插画风格 + 近景 + 高清，超细节


## 5. RAG

RAG是一个外部知识库，能在不改变模型参数的情况下，对模型进行调优。  

大模型能通过以下方式**学习知识**：  
- 预训练时，从训练数据中学习
- API调用（如天气API）
- RAG（多源检索，如网页/数据库/API）
- 插件


### 5.1 如何构建RAG知识库

本质是将用户提供的文档，整理并保存到**向量数据库**中。  



### 5.2 如何调用RAG

通过LangChain等架构工具，在编排的工作流中增加对RAG的调用。  

### 5.3 大模型生成回答的原理

1. 用户实时问题 ---> 用户提示词
2. 知识库 ---> 知识提示词
3. 任务定制 ---> 系统提示词 
4. LLM获取上面的3种提示词，最终整合成回答

### 5.4 RAG的发展
- Native RAG（固定流程，直接从向量数据库查询，并且结合系统提示词、用户提示词生成回答）
- Advanced RAG（Native RAG基础上，增加了重排、过滤等步骤。依然是固定流程）
- Modular RAG（将阅读、搜索、重写、过滤等能力模块化，并且由大模型决定执行流程）

